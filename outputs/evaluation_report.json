{
  "overall": {
    "accuracy": 0.9404258610022685,
    "precision": 0.6848860686472454,
    "recall": 0.9741538461538461,
    "f1": 0.8043018037090355,
    "auc_roc": 0.9896163076832356,
    "auc_pr": 0.932165378857072,
    "brier_score": 0.04242659623563093,
    "precision_at_10pct": 0.9131219386439804,
    "precision_at_20pct": 0.6203918535705079,
    "lift_at_10pct": 7.2660156397697,
    "true_positives": 4749,
    "false_positives": 2185,
    "true_negatives": 31732,
    "false_negatives": 126
  },
  "by_cohort": [
    {
      "accuracy": 0.9409360096431004,
      "precision": 0.643918918918919,
      "recall": 0.9631126831733199,
      "f1": 0.7718161571168253,
      "auc_roc": 0.9884563557631116,
      "auc_pr": 0.9128712935369182,
      "brier_score": 0.041591475559793915,
      "precision_at_10pct": 0.8459119496855346,
      "precision_at_20pct": 0.5136268343815513,
      "lift_at_10pct": 8.156061602804288,
      "true_positives": 1906,
      "false_positives": 1054,
      "true_negatives": 16048,
      "false_negatives": 73,
      "cohort": "mature",
      "n_samples": 19081,
      "churn_rate": 0.10371573816885908
    },
    {
      "accuracy": 0.9393923869050669,
      "precision": 0.7010309278350515,
      "recall": 0.9807692307692307,
      "f1": 0.8176352705410822,
      "auc_roc": 0.990500708633986,
      "auc_pr": 0.9432764466671697,
      "brier_score": 0.04351119798172259,
      "precision_at_10pct": 0.9451563300871348,
      "precision_at_20pct": 0.6810146041506533,
      "lift_at_10pct": 6.822672487785053,
      "true_positives": 2652,
      "false_positives": 1131,
      "true_negatives": 15684,
      "false_negatives": 52,
      "cohort": "established",
      "n_samples": 19519,
      "churn_rate": 0.1385316870741329
    },
    {
      "accuracy": 0.9947916666666666,
      "precision": 1.0,
      "recall": 0.9947916666666666,
      "f1": 0.9973890339425587,
      "auc_roc": 0.0,
      "auc_pr": 0.0,
      "brier_score": 0.015158867765228873,
      "precision_at_10pct": 1.0,
      "precision_at_20pct": 1.0,
      "lift_at_10pct": 1.0,
      "true_positives": 191,
      "false_positives": 0,
      "true_negatives": 0,
      "false_negatives": 1,
      "cohort": "new_user",
      "n_samples": 192,
      "churn_rate": 1.0
    }
  ],
  "by_ltv_tier": [
    {
      "accuracy": 0.9531827162614895,
      "precision": 0.7389558232931727,
      "recall": 0.9832999331997327,
      "f1": 0.8437947836056177,
      "auc_roc": 0.9930549848382358,
      "auc_pr": 0.9534496619424053,
      "brier_score": 0.03364822498060028,
      "precision_at_10pct": 0.9407216494845361,
      "precision_at_20pct": 0.6387457044673539,
      "lift_at_10pct": 7.315257663092508,
      "true_positives": 1472,
      "false_positives": 520,
      "true_negatives": 9624,
      "false_negatives": 25,
      "ltv_tier": "mid_market",
      "n_samples": 11641,
      "churn_rate": 0.12859719955330298
    },
    {
      "accuracy": 0.9838831528582221,
      "precision": 0.8976234003656307,
      "recall": 0.9839679358717435,
      "f1": 0.9388145315487572,
      "auc_roc": 0.9977125910807791,
      "auc_pr": 0.9904126209350639,
      "brier_score": 0.012128481710419234,
      "precision_at_10pct": 0.9899244332493703,
      "precision_at_20pct": 0.6259445843828715,
      "lift_at_10pct": 7.8777353195055095,
      "true_positives": 491,
      "false_positives": 56,
      "true_negatives": 3416,
      "false_negatives": 8,
      "ltv_tier": "enterprise",
      "n_samples": 3971,
      "churn_rate": 0.12566104255854949
    },
    {
      "accuracy": 0.9265746333045729,
      "precision": 0.6339021615472128,
      "recall": 0.9676971170545329,
      "f1": 0.7660159472092384,
      "auc_roc": 0.9854016691036785,
      "auc_pr": 0.9026270123808611,
      "brier_score": 0.052025510496175674,
      "precision_at_10pct": 0.8805004314063848,
      "precision_at_20pct": 0.6065573770491803,
      "lift_at_10pct": 7.089267106634248,
      "true_positives": 2786,
      "false_positives": 1609,
      "true_negatives": 18692,
      "false_negatives": 93,
      "ltv_tier": "smb",
      "n_samples": 23180,
      "churn_rate": 0.12420189818809318
    }
  ],
  "optimal_threshold": 0.8134809132918083,
  "threshold_metrics": {
    "threshold": 0.8134809132918083,
    "precision": 0.8403034429099397,
    "recall": 0.8861538461538462,
    "f1": 0.8626198083067093
  },
  "business_impact": {
    "true_positives": 4320,
    "false_positives": 821,
    "false_negatives": 555,
    "true_negatives": 33096,
    "total_interventions": 5141,
    "intervention_cost": 257050.0,
    "expected_saved_revenue": 87111929.228,
    "lost_revenue": 15488532.200000001,
    "net_benefit": 86854879.228,
    "roi": 337.890990966738
  }
}