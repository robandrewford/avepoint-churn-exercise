# Model Configuration for Churn Prediction
# AvePoint Principal Applied Scientist Exercise

data:
  # Synthetic data parameters
  n_customers: 50000
  n_months_history: 12
  random_seed: 42
  
  # Churn rates by cohort (baseline)
  churn_rates:
    new_user: 0.25      # Higher churn for new users
    established: 0.12   # Moderate for established
    mature: 0.08        # Lower for mature
  
  # LTV distribution
  ltv_tiers:
    smb:
      proportion: 0.60
      monthly_revenue_range: [200, 800]
      weight: 1.0
    mid_market:
      proportion: 0.30
      monthly_revenue_range: [1500, 5000]
      weight: 3.0
    enterprise:
      proportion: 0.10
      monthly_revenue_range: [10000, 30000]
      weight: 10.0

cohorts:
  # Cohort definitions (tenure in days)
  new_user:
    min_tenure: 0
    max_tenure: 30
    observation_window: 14
    prediction_horizon: 30
  established:
    min_tenure: 31
    max_tenure: 180
    observation_window: 30
    prediction_horizon: 30
  mature:
    min_tenure: 181
    max_tenure: null  # No upper bound
    observation_window: 60
    prediction_horizon: 90

features:
  # Feature window configurations
  windows:
    short: 7
    medium: 14
    long: 30
    extended: 60
  
  # Aggregation functions
  aggregations:
    - count
    - sum
    - mean
    - std
    - min
    - max
    - last
  
  # Velocity calculation
  velocity:
    comparison_window: 7  # Compare week-over-week

model:
  # LightGBM parameters
  lgbm:
    objective: binary
    metric: average_precision
    boosting_type: gbdt
    num_leaves: 31
    max_depth: 6
    learning_rate: 0.05
    n_estimators: 500
    min_child_samples: 20
    subsample: 0.8
    colsample_bytree: 0.8
    reg_alpha: 0.1
    reg_lambda: 0.1
    early_stopping_rounds: 50
    verbose: -1
  
  # Class imbalance handling
  class_weight: balanced
  use_sample_weights: true  # Weight by LTV

evaluation:
  # Metrics targets
  targets:
    auc_pr: 0.5
    precision_at_10pct: 0.70
    recall_at_30d: 0.60
    lead_time_days: 45
  
  # Threshold selection
  threshold_method: precision_recall_tradeoff
  default_threshold: 0.5
  
  # Cross-validation
  cv:
    n_splits: 5
    temporal: true  # Use time-series split

mlflow:
  experiment_name: churn-prediction
  tracking_uri: null  # Use default (Fabric managed)
  autolog: true
  log_models: true

monitoring:
  # Drift detection thresholds
  psi_threshold: 0.2
  ks_threshold: 0.1
  
  # Alerting
  alert_on_drift: true
  alert_on_performance_drop: true
  performance_drop_threshold: 0.10  # 10% relative drop

paths:
  data_raw: src/data/data_raw_kaggle.csv
  data_synthetic: outputs/synthetic_data.parquet
  database: outputs/churn_lakehouse.duckdb
  models: outputs/models/
  figures: outputs/figures/
