# avepoint-churn-exercise

Repo for the exercise deliverables

## Churn Prediction - AvePoint Principal Applied Scientist Exercise

A production-ready churn prediction system demonstrating ML engineering best practices, designed for the AvePoint Principal Applied Scientist interview exercise.

## ğŸ¯ Overview

This project implements a complete ML pipeline for SaaS customer churn prediction:

- **Problem Framing**: Multi-tier churn taxonomy with cohort-aware prediction windows
- **Data Engineering**: DuckDB-based medallion architecture (maps 1:1 to Microsoft Fabric)
- **Feature Engineering**: Cohort-aware features with formal leakage audit
- **Modeling**: LightGBM with LTV-weighted cost-sensitive learning
- **Explainability**: SHAP-based global and local explanations
- **Production**: MLflow tracking, monitoring framework, deployment patterns

## ğŸ“ Project Structure

```m
churn_prediction/
â”œâ”€â”€ pyproject.toml          # uv dependencies
â”œâ”€â”€ README.md
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ PLAN.md                    # Comprehensive exercise plan
â”‚   â””â”€â”€ FABRIC_DEPLOYMENT.md       # Fabric translation guide
â”œâ”€â”€ config/
â”‚   â””â”€â”€ model_config.yaml          # Model and data configuration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ generate_synthetic.py  # Synthetic data generator
â”‚   â”‚   â””â”€â”€ schema.py              # DuckDB DDL schemas
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ engineering.py         # Feature engineering
â”‚   â”‚   â””â”€â”€ leakage_audit.py       # Temporal leakage detection
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ train.py               # Training with MLflow
â”‚   â”‚   â”œâ”€â”€ evaluate.py            # Business metrics
â”‚   â”‚   â””â”€â”€ explain.py             # SHAP explanations
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ duckdb_lakehouse.py    # Medallion architecture
â”‚       â””â”€â”€ temporal_split.py      # Time-series CV
â”œâ”€â”€ notebooks/                     # Marimo notebooks (pure Python)
â”‚   â”œâ”€â”€ 01_eda.py
â”‚   â”œâ”€â”€ 02_modeling.py
â”‚   â””â”€â”€ 03_monitoring.py
â”œâ”€â”€ tests/
â””â”€â”€ outputs/
    â”œâ”€â”€ synthetic_data/            # Generated Parquet files
    â”œâ”€â”€ models/                    # Saved models
    â””â”€â”€ figures/                   # Visualizations
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- [uv](https://docs.astral.sh/uv/) (recommended) or pip

### Installation

```bash
# Clone the repository
git clone <repo-url>
cd churn_prediction

# Install dependencies with uv
uv sync

# Or with pip
pip install -e .
```

### Generate Synthetic Data

```bash
# Generate 50K customers with behavioral events
uv run python -m src.data.generate_synthetic

# Output:
# - outputs/synthetic_data/customers.parquet
# - outputs/synthetic_data/daily_engagement.parquet
# - outputs/synthetic_data/support_tickets.parquet
# - outputs/synthetic_data/login_events.parquet
```

### Run Notebooks

```bash
# EDA notebook
uv run marimo run notebooks/01_eda.py

# Modeling notebook
uv run marimo run notebooks/02_modeling.py

# Monitoring dashboard
uv run marimo run notebooks/03_monitoring.py
```

## ğŸ—ï¸ Architecture

### Data Layer: DuckDB Medallion

```m
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Bronze    â”‚â”€â”€â”€â–¶â”‚   Silver    â”‚â”€â”€â”€â–¶â”‚    Gold     â”‚
â”‚  Raw Events â”‚    â”‚  Cleaned    â”‚    â”‚  Features   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fabric Translation**: Each DuckDB schema maps to a Fabric Lakehouse. SQL is nearly identical.

### Feature Engineering

| Category | Features | Cohort |
|----------|----------|--------|
| Activation | Time-to-first-value, onboarding % | New users only |
| Engagement | Login frequency, feature adoption | All |
| Velocity | Week-over-week change, trend slope | All |
| Support | Ticket volume, sentiment, escalations | All |
| Contract | Days to renewal, value remaining | Mature |

## ğŸ“Š Key Metrics

| Metric | Target | Description |
|--------|--------|-------------|
| AUC-PR | > 0.50 | Precision-recall area (imbalanced) |
| Precision@10% | > 0.70 | CS team capacity constraint |
| Recall@30d | > 0.60 | Coverage requirement |
| Lead Time | > 45 days | Intervention window |
| Lift@10% | > 3.0x | Better than random |

## ğŸ“ˆ Microsoft Fabric Integration

This project is designed to translate directly to Fabric:

| Local (DuckDB) | Fabric Equivalent |
|----------------|-------------------|
| DuckDB schemas | Lakehouse schemas |
| Parquet files | Delta tables |
| Python scripts | Synapse notebooks |
| MLflow (local) | Fabric MLflow |
| Marimo | Fabric notebooks |

## ğŸ§ª Testing

```bash
# Run tests
uv run pytest tests/ -v

# With coverage
uv run pytest tests/ --cov=src --cov-report=html
```

## ğŸ“š Documentation

- **[PLAN.md](docs/PLAN.md)**: Complete exercise plan (Parts 1-5)
- **[model_config.yaml](config/model_config.yaml)**: Configuration reference

## ğŸ¤ Interview Presentation

30-minute structure:

- 0:00-0:02: Opening ("Churn is solvable")
- 0:02-0:06: Problem Framing
- 0:06-0:10: Data & Features
- 0:10-0:17: Modeling (technical depth)
- 0:17-0:23: Recommendations (business impact)
- 0:23-0:28: Mentorship & Scale
- 0:28-0:30: Close + Q&A

## ğŸ“‹ Key Differentiators

1. **Cohort-Aware**: Different prediction windows for New/Established/Mature users
2. **LTV-Weighted**: Enterprise churns weighted 10x vs SMB
3. **Leakage Audit**: Formal temporal correctness verification
4. **Uplift Framework**: Prioritize "Persuadables" over "Sure Things"
5. **Production-Ready**: Monitoring, retraining triggers, escalation paths

## License

MIT
